# # -*- coding: utf-8 -*-
# """MR2J_Clasificacion.ipynb

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/17K4qeStJsjfP7IKocTsT1eW_QdkeFpKH
# """

# from google.colab import drive

# drive.mount("/content/gdrive")  
# !pwd  # show current path

# # Commented out IPython magic to ensure Python compatibility.
# # %cd "/content/gdrive/MyDrive/ClasesMachineLearning"
# !ls  # show current directory

import numpy as np
from random import randrange
import matplotlib.pyplot as plt
import math
import pandas as pd
import seaborn as sn

df = pd.read_csv('brain_stroke.csv') # Leer dataset 
df.head()

df['gender'] = df['gender'].map({'Male':0,'Female':1}) #Transformamos la información del género a 1 y 0
df['ever_married'] = df['ever_married'].map({'Yes':0,'No':1}) # Hacemos lo mismo con la info de casamientto
fSmoked = []
nSmoked = []
smokes = []
unknown = []

for i in df.values:
  if i[9] == "formerly smoked":
    fSmoked.append(1)
  else:
    fSmoked.append(0)
  if i[9] == "never smoked":
    nSmoked.append(1)
  else:
    nSmoked.append(0)
  if i[9] == "smokes":
    smokes.append(1)
  else:
    smokes.append(0)
  if i[9] == "Unknown":
    unknown.append(1)
  else:
    unknown.append(0)

df['fSmoked'] = fSmoked
df['nSmoked'] = nSmoked
df['smokes'] = smokes
df['sUnknown'] = unknown
#Transformamos las variables de fumador en variables dummy con 1 y 0 cada una
df.head()

sn.set(rc = {'figure.figsize':(25,16)})
sn.heatmap(df.corr(), annot=True, cmap= 'YlGnBu') # Revisar correlación de variables para decidir cuales entraran al modelo

df = df.drop(["work_type", "smoking_status"], axis=1)
df['Residence_type'] = df['Residence_type'].map({'Rural':0,'Urban':1})
df.head() # Eliminamos algunas columnas y cambiamos el tipo de residencia a 1 y 0

sn.set(rc = {'figure.figsize':(25,16)})
sn.heatmap(df.corr(), annot=True, cmap= 'YlGnBu') #Visualizamos la correlación de las nuevas variables

df = df.drop(["gender", "Residence_type","avg_glucose_level","nSmoked","smokes","sUnknown","bmi","fSmoked","ever_married"], axis=1)
df.head() #Eliminamos todas las variables que no influyen en nuestro resultado

sn.set(rc = {'figure.figsize':(10,5)})
sn.heatmap(df.corr(), annot=True, cmap= 'YlGnBu') # Visualizamos solo las variables utiles

df_x = df.drop(["stroke"],axis=1).values
df_y = df["stroke"].values
print(len(df_x)) #Separamos nuestra información de entrada y salida de nuestro modelo

train_y = []
train_x = []
validate_y = []
validate_x = []
for i in range(0,2988):
  value = randrange(0,len(df_y))
  train_y.append(df_y[value])
  train_x.append(df_x[value])
  df_y = np.concatenate((df_y[:value],df_y[value+1:]))
  df_x = np.concatenate((df_x[:value],df_x[value+1:]))
aux_y = df_y
aux_x = df_x
for i in range(0,997):
  value = randrange(0,len(aux_y))
  validate_y.append(aux_y[value])
  validate_x.append(aux_x[value])
  aux_y = np.concatenate((aux_y[:value],aux_y[value+1:]))
  aux_x = np.concatenate((aux_x[:value],aux_x[value+1:]))
train_x = aux_x
train_y = aux_y
#Aleatoriamente tomamos 4000 valores de nuestros datos para entrenar y dejamos los otros 981 para validar

h   = lambda x,theta: 1 / (1+math.exp(-(theta[0]+theta[1]*x[0]+theta[2]*x[1]+theta[3]*x[2])))
j_i = lambda x,y,theta: y*math.log(h(x,theta)) + (1-y)*math.log(1-h(x,theta)) #Creamos nuestra función h y nuestra función de costo

theta = [1,1,1,1] #Cambia dependiendo del orden del modelo (1 theta para cada dimensión de nuestros datos + 1)
alpha = 0.00001
n = len(train_y)
print(theta) #Realizamos 2000 iteraciones con un alpha de 10
for idx in range(5000):
  acumDelta0 = []
  acumDelta1 = []
  acumDelta2 = []
  acumDelta3 = []
  for x_i, y_i in zip(train_x,train_y):
    acumDelta0.append(h(x_i,theta)-y_i)
    acumDelta1.append((h(x_i,theta)-y_i)*x_i[0])
    acumDelta2.append((h(x_i,theta)-y_i)*x_i[1])
    acumDelta3.append((h(x_i,theta)-y_i)*x_i[2])
  sJt0 = sum(acumDelta0)
  sJt1 = sum(acumDelta1)
  sJt2 = sum(acumDelta2)
  sJt3 = sum(acumDelta3)
  theta[0] = theta[0] - (alpha/n)*sJt0
  theta[1] = theta[1] - ((alpha/n)*sJt1)
  theta[2] = theta[2] - ((alpha/n)*sJt2)
  theta[3] = theta[3] - ((alpha/n)*sJt3)
print(theta)

n_train = len(train_y)
n_validate = len(validate_y)

#Validación
acumDelta = []
for x_i, y_i in zip(validate_x,validate_y):
    acumDelta.append(j_i(x_i,y_i,theta))

sDelta = sum(acumDelta)
j_validate = 1/(2*n_validate)*sDelta

print("Error de validación: ",j_validate)

#Training
acumDelta = []
for x_i, y_i in zip(train_x,train_y):
    acumDelta.append(j_i(x_i,y_i,theta))

sDelta = sum(acumDelta)
j_train = 1/(2*n_train)*sDelta

print("Error de entrenamiento: ",j_train)
print(theta)
#Obtenemos el error el cual es muy pequeño

print(df)

def predict(x,expected):
  res = h(x,theta)
  exp = 0
  #if (expected==1):print(res,expected)
  if res<0.5:
    exp =  0
  else:
    exp = 1
  if exp == expected:
    return 1
  else:
    return 0


#Creamos una función que de acuerdo al resultado de nuestro modelo pueda predecir un resultado, compararlo con nuestro resultado esperado
#Y retornar si el modelo predijo bien o no, si predice bien retorna 1 y si predice mal retorna 0

#Para redondear, ya que queremos resultados de 1 y 0, si el valor es menor a 0.5, asumimos un 0 y si es mayor a 0.5 asumimos un 1


def predictMC(x,expected):
  res = h(x,theta)
  exp = 0
  if res<0.5:
    exp =  0
  else:
    exp = 1
  if exp == 1:
    if expected ==1:
      return "VP"
    else:
      return "FP"
  else:
    if expected ==0:
      return "VN"
    else:
      return "FN"


# Creamos la función predictMc, que nos permite saber si el valor actual devuelve un Verdadero positivo, un Falso positivo, Un verdadero negativo o un falso negativo

valid_y = validate_y
valid_x = validate_x
good = 0
bad = 0
l = 981
mC = [[0,0],[0,0]]
for i in range(0,100):
  n = randrange(0,len(valid_y))
  mcValue = predictMC(valid_x[n],valid_y[n])
  if mcValue == "VP": mC[0][0]+= 1
  if mcValue == "FP": mC[0][1]+= 1
  if mcValue == "FN": mC[1][0]+= 1
  if mcValue == "VN": mC[1][1]+= 1
  if predict(valid_x[n],valid_y[n]) == 1:
    good+=1
  else:
    bad+=1
  valid_x = np.concatenate((valid_x[:n],valid_x[n+1:]))
  valid_y = np.concatenate((valid_y[:n],valid_y[n+1:]))
  l-=1
print(good,bad)
print(mC)
# Aleatoriamente seleccionamos 100 valores de nuestra muestra de validación y los metemos al modelo para saber cuantas 
# veces predice correctamente y cuantas se equivoca

efectividad = [good, bad]
titulo = ["Procentaje de predicciones correctas", "Porcentaje de predicciones incorrectas"]
plt.title("Predicciones")
plt.pie(efectividad, labels=titulo, autopct="%0.0f %%")
plt.show()
#Graficamos el porcentaje de aciertos de nuestro modelo y podemos visualizar que es un buen número

mcData = [mC[0][0], mC[0][1],mC[1][0],mC[1][1]]
titulo = ["VP", "FP","FN","VN"]
plt.title("Matriz de confusión")
plt.pie(mcData, labels=titulo, autopct="%0.0f %%")
plt.show()

"""# Calculo de la varianza"""

from scipy.stats import skew

results=[]
def varianza(x,expected):
  res = h(x,theta)
  results.append(res)
  dif = (res - expected)**2
  return dif

sumVar = 0
valid_y = validate_y
valid_x = validate_x
for i in range(0,981):
  sumVar+=varianza(valid_x[i],valid_y[i])
print(sumVar/981)

print(skew(results))

"""# Modelo refinado"""

h   = lambda x,theta: float(1 / (1+math.exp(-(theta[0]+theta[1]*x[0]+theta[2]*x[1]+theta[3]*x[2]+theta[4]*x[3]))))
j_i = lambda x,y,theta: y*math.log(h(x,theta)) + (1-y)*math.log(1-h(x,theta))

"""# Limpieza de datos"""

df = pd.read_csv('brain_stroke.csv') # Leer dataset 
df['gender'] = df['gender'].map({'Male':0,'Female':1}) #Transformamos la información del género a 1 y 0
df['ever_married'] = df['ever_married'].map({'Yes':0,'No':1}) # Hacemos lo mismo con la info de casamientto
fSmoked = []
nSmoked = []
smokes = []
unknown = []

for i in df.values:
  if i[9] == "formerly smoked":
    fSmoked.append(1)
  else:
    fSmoked.append(0)
  if i[9] == "never smoked":
    nSmoked.append(1)
  else:
    nSmoked.append(0)
  if i[9] == "smokes":
    smokes.append(1)
  else:
    smokes.append(0)
  if i[9] == "Unknown":
    unknown.append(1)
  else:
    unknown.append(0)

df['fSmoked'] = fSmoked
df['nSmoked'] = nSmoked
df['smokes'] = smokes
df['sUnknown'] = unknown
df = df.drop(["work_type", "smoking_status"], axis=1)
df['Residence_type'] = df['Residence_type'].map({'Rural':0,'Urban':1})
df = df.drop(["gender", "Residence_type","nSmoked","smokes","sUnknown","bmi","fSmoked","ever_married"], axis=1)
df_x = df.drop(["stroke"],axis=1).values
df_y = df["stroke"].values
train_y = []
train_x = []
validate_y = []
validate_x = []
for i in range(0,2988):
  value = randrange(0,len(df_y))
  train_y.append(df_y[value])
  train_x.append(df_x[value])
  df_y = np.concatenate((df_y[:value],df_y[value+1:]))
  df_x = np.concatenate((df_x[:value],df_x[value+1:]))
aux_y = df_y
aux_x = df_x
for i in range(0,997):
  value = randrange(0,len(aux_y))
  validate_y.append(aux_y[value])
  validate_x.append(aux_x[value])
  aux_y = np.concatenate((aux_y[:value],aux_y[value+1:]))
  aux_x = np.concatenate((aux_x[:value],aux_x[value+1:]))
train_x = aux_x
train_y = aux_y

"""# Implementación modelo"""

print(len(train_y),len(train_x))

theta = [1,1,1,1,1] #Cambia dependiendo del orden del modelo (1 theta para cada dimensión de nuestros datos + 1)
alpha = 0.001
n = len(train_y)
print(theta) #Realizamos 2000 iteraciones con un alpha de 10
for idx in range(100):
  acumDelta0 = []
  acumDelta1 = []
  acumDelta2 = []
  acumDelta3 = []
  acumDelta4 = []
  for x_i, y_i in zip(train_x,train_y):
    acumDelta0.append(h(x_i,theta)-y_i)
    acumDelta1.append((h(x_i,theta)-y_i)*x_i[0])
    acumDelta2.append((h(x_i,theta)-y_i)*x_i[1])
    acumDelta3.append((h(x_i,theta)-y_i)*x_i[2])
    acumDelta4.append((h(x_i,theta)-y_i)*x_i[3])
  sJt0 = sum(acumDelta0)
  sJt1 = sum(acumDelta1)
  sJt2 = sum(acumDelta2)
  sJt3 = sum(acumDelta3)
  sJt4 = sum(acumDelta4)
  theta[0] = theta[0] - (alpha/n)*sJt0
  theta[1] = theta[1] - ((alpha/n)*sJt1)
  theta[2] = theta[2] - ((alpha/n)*sJt2)
  theta[3] = theta[3] - ((alpha/n)*sJt3)
  theta[4] = theta[4] - ((alpha/n)*sJt4)
print(theta)

n_train = len(train_y)
n_validate = len(validate_y)

#Validación
acumDelta = []
for x_i, y_i in zip(validate_x,validate_y):
    acumDelta.append(j_i(x_i,y_i,theta))

sDelta = sum(acumDelta)
j_validate = 1/(2*n_validate)*sDelta

print("Error de validación: ",j_validate)

#Training
acumDelta = []
for x_i, y_i in zip(train_x,train_y):
    acumDelta.append(j_i(x_i,y_i,theta))

sDelta = sum(acumDelta)
j_train = 1/(2*n_train)*sDelta

print("Error de entrenamiento: ",j_train)
print(theta)
#Obtenemos el error el cual es muy pequeño

def predict(x,expected):
  res = h(x,theta)
  exp = 0
  #if (expected==1):print(res,expected)
  if res<0.5:
    exp =  0
  else:
    exp = 1
  if exp == expected:
    return 1
  else:
    return 0


#Creamos una función que de acuerdo al resultado de nuestro modelo pueda predecir un resultado, compararlo con nuestro resultado esperado
#Y retornar si el modelo predijo bien o no, si predice bien retorna 1 y si predice mal retorna 0

#Para redondear, ya que queremos resultados de 1 y 0, si el valor es menor a 0.5, asumimos un 0 y si es mayor a 0.5 asumimos un 1


def predictMC(x,expected):
  res = h(x,theta)
  exp = 0
  if res<0.5:
    exp =  0
  else:
    exp = 1
  if exp == 1:
    if expected ==1:
      return "VP"
    else:
      return "FP"
  else:
    if expected ==0:
      return "VN"
    else:
      return "FN"

valid_y = validate_y
valid_x = validate_x
good = 0
bad = 0
l = 981
mC = [[0,0],[0,0]]
for i in range(0,100):
  n = randrange(0,len(valid_y))
  mcValue = predictMC(valid_x[n],valid_y[n])
  if mcValue == "VP": mC[0][0]+= 1
  if mcValue == "FP": mC[0][1]+= 1
  if mcValue == "FN": mC[1][0]+= 1
  if mcValue == "VN": mC[1][1]+= 1
  if predict(valid_x[n],valid_y[n]) == 1:
    good+=1
  else:
    bad+=1
  valid_x = np.concatenate((valid_x[:n],valid_x[n+1:]))
  valid_y = np.concatenate((valid_y[:n],valid_y[n+1:]))
  l-=1
print(good,bad)
print(mC)
# Aleatoriamente seleccionamos 100 valores de nuestra muestra de validación y los metemos al modelo para saber cuantas 
# veces predice correctamente y cuantas se equivoca

efectividad = [good, bad]
titulo = ["Procentaje de predicciones correctas", "Porcentaje de predicciones incorrectas"]
plt.title("Predicciones")
plt.pie(efectividad, labels=titulo, autopct="%0.0f %%")
plt.show()
#Graficamos el porcentaje de aciertos de nuestro modelo y podemos visualizar que es un buen número

mcData = [mC[0][0], mC[0][1],mC[1][0],mC[1][1]]
titulo = ["VP", "FP","FN","VN"]
plt.title("Matriz de confusión")
plt.pie(mcData, labels=titulo, autopct="%0.0f %%")
plt.show()

results=[]
def varianza(x,expected):
  res = h(x,theta)
  results.append(res)
  dif = (res - expected)**2
  return dif

sumVar = 0
valid_y = validate_y
valid_x = validate_x
for i in range(0,981):
  sumVar+=varianza(valid_x[i],valid_y[i])
print(sumVar/981)

print(skew(results))